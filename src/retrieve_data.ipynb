{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script retrieves monthly pageview counts on dinosaur wikipedia pages:\n",
    "- it gets a list of article titles from 'raw_data/dinosaur_article_titles.csv'\n",
    "- it runs those through the Wikipedia API to get the pageview counts\n",
    "- it saves the resulting data to 'raw_data/dino_monthly_\\<access_type\\>_201501-202209.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for calling the Wikipedia API is based on [this example notebook](https://drive.google.com/file/d/1gtFZAjRoOShsqZKuNhiiSn9Ko4ky-CSC/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file 'raw_data/dinosaur_article_titles.csv' was downloaded from [this file](https://docs.google.com/spreadsheets/d/1zfBNKsuWOFVFTOGK8qnTr2DmHkYK4mAACBKk1sHLt_k/edit?usp=sharing). No changes were made besides renaming the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Constants are variables that will not be changed later in the script.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_PATH = '../raw_data/dinosaur_article_titles.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location of the CSV file of article titles to be used - see [Preprocessing](#Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a parameterized string that specifies what kind of pageviews request we are going to make.  \n",
    "In this case it will be a 'per-article' based request. The string is a format string so that we can replace each parameter with an appropriate value before making the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<klein324@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2022',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making a request to the Wikimedia API they ask that you include a \"unique ID\" that will allow them to contact you if something happens - such as - your code exceeding request limits - or some other error happens.  \n",
    "**NOTE: this should be replaced with your own email and usage information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"\",             # this value will be set/changed before each request\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",\n",
    "    \"end\":         \"2022093000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. The dictionary has a field/key for each of the required parameters. In the example, below, we only vary the article name and access type, so the majority of the fields can stay constant for each request. Of course, these values *could* be changed if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to request pageviews for 1 article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes inputs of all the information needed to access the API and outputs the json response unmodified *except* it removes the 'access' field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "- article_title: the title of a Wikipedia article\n",
    "- access_type: the method(s) the page was accessed by to be included in viewcount\n",
    "    - Available values : all-access, desktop, mobile-app, mobile-web\n",
    "- endpoint_url: the REST API 'pageviews' URL\n",
    "- endpoint_params: a parameterized string that specifies what kind of pageviews request to make - see [documentation](https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end)\n",
    "- request_template: a template used to map parameter values into endpoint_params\n",
    "- headers: a unique ID for the request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "- a json response of a list of dictionaries, with each dictionary being one month's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_pageviews_per_article(article_title = None, \n",
    "                                  access_type = \"desktop\",\n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # Make sure we have an article title\n",
    "    if not article_title: return None\n",
    "    \n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(article_title.replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    # update the access type\n",
    "    request_template['access'] = access_type\n",
    "    \n",
    "    # create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "        \n",
    "        # remove access type from dictionary\n",
    "        for item in json_response[\"items\"]:\n",
    "            del item[\"access\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compile all pageview data for one access type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a list of article titles and a newly-defined access type, and outputs a dictionary of data from the API (using the previous function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "- article_list: a list of titles of Wikipedia articles\n",
    "- access_type: the method(s) the page was accessed by to be included in viewcount\n",
    "    - Available values : desktop, mobile (sum of mobile-app and mobile-web), cumulative (all-access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "- a dictionary with the keys being the article names and values being the list of dictionaries from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_pageview_data(article_list, access = \"desktop\"):\n",
    "    article_dict = {}\n",
    "    \n",
    "    # loop through article titles\n",
    "    for title in article_list:\n",
    "        if access == \"desktop\":\n",
    "            # get API data with 'desktop' access type\n",
    "            article_dict[title] = request_pageviews_per_article(article_title = title, access_type = \"desktop\")\n",
    "            \n",
    "        elif access == \"mobile\":\n",
    "            # get API data from both 'mobile-app' and 'mobile-web' access types\n",
    "            app = request_pageviews_per_article(article_title = title, access_type = \"mobile-app\")\n",
    "            web = request_pageviews_per_article(article_title = title, access_type = \"mobile-web\")\n",
    "            # loop through both lists simultaniously, and add the viewcount from 'mobile-web' to 'mobile-app'\n",
    "            for d in zip(app[\"items\"], web[\"items\"]):\n",
    "                d[0]['views'] = d[0]['views'] + d[1]['views']\n",
    "            article_dict[title] = app\n",
    "            \n",
    "        elif access == \"all-access\":\n",
    "            # get API data with 'desktop' access type\n",
    "            article_dict[title] = request_pageviews_per_article(article_title = title, access_type = \"all-access\")\n",
    "            \n",
    "    return(article_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = pd.read_csv(TITLE_PATH)['name'].tolist()\n",
    "title_list = [item.replace('“','\\\"').replace('”','\\\"') for item in title_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the file of article names and convert to a list  \n",
    "also replace incorrect quote characters (“,”) with **\\\\\\\"** to be correctly read by the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = compile_pageview_data(title_list, access = \"mobile\")\n",
    "desktop = compile_pageview_data(title_list, access = \"desktop\")\n",
    "cumulative  = compile_pageview_data(title_list, access = \"cumulative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get data for all titles in list for mobile, desktop, and all (cumulative) access types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_json = json.dumps(mobile, indent=4)\n",
    "desktop_json = json.dumps(desktop, indent=4)\n",
    "cumulative_json = json.dumps(cumulative, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialize the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../raw_data/dino_monthly_mobile_201501-202209.json\", \"w\") as outfile:\n",
    "    outfile.write(mobile_json)\n",
    "with open(\"../raw_data/dino_monthly_desktop_201501-202209.json\", \"w\") as outfile:\n",
    "    outfile.write(desktop_json)\n",
    "with open(\"../raw_data/dino_monthly_cumulative_201501-202209.json\", \"w\") as outfile:\n",
    "    outfile.write(cumulative_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the data into the 'raw_data' folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
